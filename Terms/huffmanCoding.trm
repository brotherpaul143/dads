# *created  "Wed Feb  3 13:42:31 1999" *by "Paul E. Black"
# *modified "Mon Jan 11 10:03:57 2021" *by "Paul E. Black"

# $Log: huffmanCoding.trm,v $
# Mon Jan 11 10:05:28 2021  Paul E. Black
# Remove URL for Alex Vinokur NOTE; I can no longer find it.
# 
# Mon Apr  1 09:04:00 2019  Paul E. Black
# Update URL for Alistair Moffats IMPL
# 
# Mon Feb 11 17:10:12 2019  Paul E. Black
# use https to access Wikipedia
# 
# Revision 1.16  2011/12/12 15:05:23  black
# Remove IMPL from Numerical Recipes in C - files are gone.
#
# Revision 1.15  2011/05/26 19:52:18  black
# Reference the new entry, level.  Improve DEFN a little.
#
# Revision 1.14  2010/02/01 22:01:15  black
# update Alistair's IMPL URL
#
# Revision 1.13  2007/04/30 15:32:42  black
# IMA greddy algorithm.  Coding tree is INME.  Refer to DADS prefix code
# entry, and move Wikipedia entry to DADS entry.
#
# Revision 1.12  2006/12/05 16:03:41  black
# XREF order-preserving Huffman coding.  LINK wikipedia prefix code
# article.  Add WEB name: compression.  Improve defn wording a bit.
#
# Revision 1.11  2006/11/20 14:27:15  black
# Add IMPL from Numerical Recipes in C.  Improve NOTE wording.
#
# Revision 1.10  2005/10/27 14:05:27  black
# Rename file to huffmanCoding.  Update John Morris' URL.  Comment on
# Alistair Moffat's location, to find him if the URL changes.
#
# Revision 1.9  2005/03/07 15:07:06  black
# Update Vinokur's MathForum URL.
#
# Revision 1.8  2005/02/02 20:25:40  black
# IM not A greedy algorithm; it is an algo. technique used INME.
#
# Revision 1.7  2005/01/10 16:49:56  black
# Fix typo in Vinokur's URL in NOTES.
#
# Revision 1.6  2005/01/04 15:28:17  black
# Remove Vermeer's URL - gone.  Fix typo.  Show John Morris' name.
#
# Revision 1.5  2004/12/23 21:34:36  black
# Remove bad trailing space in VARIANT.
#
# Revision 1.4  2004/12/17 17:24:01  black
# Make more XHTML compliant.
#
# Revision 1.3  2004/11/01 16:40:14  black
# Change encoding to coding.  Improve DEF'N.  Add original BIB and links
# to Wikipedia.
#
# Revision 1.2  2004/10/29 13:23:35  black
# Refine XREFS into IMA, etc.  Add RCS keywords.
#

# entry name
@NAME=Huffman coding
# _A_lgorithm, _D_efinition, _P_roblem, or data _S_tructure
@TYPE=A
# basic, numeric, search, sort, graph, combin(atorial), tree, theory
@AREA=crypt
# the definition
@DEFN=A minimal variable-length character coding based on the frequency of 
each character.  First, each character becomes a one-node
{binary tree}, with the
character as the only {node}.  The character's frequency is the tree's
frequency.  Two trees with the least frequencies are joined as the
subtrees of a
new root that is assigned the sum of their frequencies.
Repeat until all characters are in one tree.  One code bit represents
each {level}.  Thus more frequent characters are near the {root} and
are coded with few bits, and rare characters are far from the root
and are coded with many bits.
# formal definition or {cross reference} to an entry
@FORML=
# comma-sep list of pure names that this is Also Known As.
@AKA=static Huffman coding
# other cross-listings solely for the web, such as word or spelling variants
@WEB=Huffman encoding, Hufman encoding, Huffmann compression

#    These are all comma-separated lists of {cross references}
# Generalization: "I am a kind of ..."
@IMA={greedy algorithm}
# Specialization: "... is a kind of me."
@VARIANT={adaptive Huffman coding}, {k-ary Huffman coding}
# Aggregate parent: "I am a part of or used in ..."
@IMIN=
# Aggregate child: "... is a part of or used in me."
@INME={coding tree}, {full binary tree}, {priority queue}
# Other cross references that don't fit the above.  printed as "See also ..."
@XREFS={order-preserving Huffman coding}, {arithmetic coding}, 
{optimal merge}, {Shannon-Fano coding}

# bib refs, eg, to defining article (pure HTML).  printed within <p>..</p>
@BIB=
<strong>David A. Huffman</strong>, <em>A Method for The Construction
of Minimum Redundancy Codes</em>, 
Proceedings of IRE, 40(9):1098-1101, September 1952.

# any notes.  these will not be printed in the final dictionary
@NOTES=
The {worst case} for Huffman coding (or, equivalently, the longest
Huffman coding for a set of characters) is when the distribution
of frequencies follows the {Fibonacci numbers}.  (This and other
relations came from Alex Vinokur
"Fibonacci numbers, Lucas numbers and Huffman codes".)
</p>

<p>
Joining trees by frequency is the same as merging sequences by length
in {optimal merge}.  See the example there.
Since a node with only one child is not optimal, any Huffman
coding corresponds to a {full binary tree}.
</p>

<p>
Huffman coding is one of many <a
href="https://en.wikipedia.org/wiki/Category:Lossless_compression_algorithms">lossless
compression algorithms</a>.  This algorithm produces a {prefix code}.
</p>

<p>
Shannon-Fano is a minimal prefix code. Huffman is optimal for
character coding (one character-one code word) and simple to
program.  Arithmetic coding is even more compact, since it can
allocate fractional bits, but is more complicated and patents cover
some uses.
# further explanation (pure HTML)
@LINKS=
A
<a
href="http://www.ics.uci.edu/~dan/pubs/DC-Sec3.html">survey on data
compression</a>,
John Morris'
# morris@ee.uwa.edu.au
<a
href="http://www.cs.auckland.ac.nz/software/AlgAnim/huffman.html">explanation,
example, and analysis</a>.
Wikipedia's encyclopedic article on
<a href="https://en.wikipedia.org/wiki/Huffman_coding">Huffman
coding</a>.
# implementation(s) (pure HTML)
@IMPL=
# Alistair Moffat, ammoffat@unimelb.edu.au
# University of Melbourne, Victoria
# "In-Place Calculation of Minimum-Redundancy Codes"
#       ... Huffman's famous greedy algorithm solves this problem ...
<a href="https://people.eng.unimelb.edu.au/ammoffat/abstracts/mk95wads.html">build
tree in array (C)</a> --  also computes entropy and efficiency.
# author's initials
@AUTHOR=PEB
# end $Source: /home/black/Workspace/dads/Terms/RCS/huffmanCoding.trm,v $
