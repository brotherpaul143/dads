# *created  "Tue Apr 11 11:27:20 2000" *by "Paul E. Black"
# *modified "Thu Dec  9 11:48:21 2004" *by "Paul E. Black"

# $Log: hiddenMarkovModel.trm,v $
# Revision 1.6  2004/12/09 16:48:51  black
# Fix typo
#
# Revision 1.5  2004/12/08 16:25:23  black
# NOTE who Markov is.
#
# Revision 1.4  2004/12/08 15:57:17  black
# Add BIB entry
#
# Revision 1.3  2004/07/07 16:10:21  black
# Remove link to Cohen's lecture 19, since it only renders in IE.
#
# Revision 1.2  2004/07/06 13:06:11  black
# Refine XREFS into IMA, etc. and add RCS keywords.  Update Cohen URL.
#

# entry name
@NAME=hidden Markov model
# _A_lgorithm, algo _T_echnique, _D_efinition, _P_roblem, or data _S_tructure
@TYPE=S
# autom basic theory search sort tree graph combin numeric etc. see areas.data
@AREA=graph
# the definition
@DEFN=A variant of a {finite state machine} having a set of {states},
Q, an output {alphabet}, O, transition probabilities, A, output
probabilities, B, and initial state probabilities, $\Pi$.  The current
state is not observable.  Instead, each state produces an output
with a certain probability (B).  Usually the states, Q, and
outputs, O, are understood, so an HMM is said to be a triple, 
$(A, B, \Pi)$.
# formal definition or {cross reference} to an entry
@FORML=
After Michael Cohen's lectures for 
<A href="http://screwdriver.bu.edu/">CN760</A>.
<ul>
<li> $A = \{a<sub>ij</sub> = P(q<sub>j</sub> at t+1 | q<sub>i</sub> at
t)}$, where $P(a | b)$ is the conditional probability of a given b, 
$t \geq 1$ is time, and $q<sub>i</sub> \in Q$.
<br>Informally, A is the probability that the next state is $q<sub>j</sub>$
given that the current state is $q<sub>i</sub>$.
<li> $B = \{b<sub>ik</sub> = P(o<sub>k</sub> | q<sub>i</sub>)}$, 
where $o<sub>k</sub> \in O$.
<br>Informally, B is the probability that the output is
$o<sub>k</sub>$ given that the current state is $q<sub>i</sub>$.
<li> $\Pi = \{p<sub>i</sub> = P(q<sub>i</sub> at t=1)}$.
</ul>
# comma-sep list of pure names or {cross refs} that this is Also Known As.
@AKA=HMM
# other cross-listings solely for the web, such as word or spelling variants
@WEB=

#    These are all comma-separated lists of {cross references}
# Generalization: "I am a kind of ..."
@IMA={finite state machine}
# Specialization: "... is a kind of me."
@VARIANT=
# Aggregate parent: "I am a part of or used in ..."
@IMIN={Baum Welch algorithm}, {Viterbi algorithm}
# Aggregate child: "... is a part of or used in me."
@INME=
# Other cross references that don't fit the above.  printed as "See also ..."
@XREFS={Markov chain}

# bib refs, eg, to defining article (pure HTML).  printed within <P>..</P>
@BIB=
# this might not be *the* defining article, but it is early and by the
# originator, Baum
<strong>L. E. Baum</strong>, <em>An inequality and associated
maximization technique in statistical estimation for probabilistic
functions of Markov processes</em>, Inequalities, 3:1-8, 1972.

# any notes.  these will not be printed in the final dictionary
@NOTES=Computing a model given sets of sequences of observed outputs
is very difficult, since the states are not directly observable and
transitions are probabilistic.  One method is the {Baum Welch
algorithm}.
</P>

<P>
Although the states cannot, by definition, be directly observed,
the most likely sequence of sets for a given sequence of observed
outputs can be computed in O(nt), where n is the number of states and
t is the length of the sequence.  One method is the {Viterbi
algorithm}.
</P>

<P>
Thanks to Arvind &lt;uk_arvind@mail.utexas.edu&gt; May 2002.
</P>

<P>
Named after
<A href="http://www-history.mcs.st-andrews.ac.uk/history/Mathematicians/Markov.html">Andrei 
Andreyevich Markov</A> (1856 - 1922), who studied poetry and other
texts as stochastic sequences of characters.

# further explanation (pure HTML)
@LINKS=
# search words: Center for Adaptive Systems, Stationary
# Markov Chains, Weather Model, Hidden Markov Model, Markov Chain, Urn Model
# implementation(s) (pure HTML)
@IMPL=
# author's initials (see authors.data)
@AUTHOR=PEB
# end $Source: /home/black/Workspace/dads/Terms/RCS/hiddenMarkovModel.trm,v $
