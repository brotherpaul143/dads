# *created  "Wed Feb  3 13:42:31 1999" *by "Paul E. Black"
# *modified "Mon Jun 14 09:35:02 2004" *by "Paul E. Black"

# $Log: bigOnotation.trm,v $
# Revision 1.3  2004/06/14 13:37:32  black
# Refine XREFS into IMA, etc.  Add RCS keywords.  Add WEB name Landau
# symbol and link to MathWorld entry.  Refer to Lueker's "Notation".
# Add BIB entry.
#
# Revision 1.2  2003/09/04 21:25:33  black
# Remove a site no longer found anywhere that I could find
#

# entry name
@NAME=big-O notation
# _A_lgorithm, _D_efinition, _P_roblem, or data _S_tructure
@TYPE=D
# basic numeric search sort graph combin(atorial) tree theory para(llel)
@AREA=basic
# the definition
@DEFN=A theoretical measure of the execution of an {algorithm},
usually the time or memory needed, given the problem size $n$,
which is usually the number of items.  Informally, saying some equation
$f(n) = O(g(n))$ means it is less than some constant
multiple of $g(n)$.    
The notation is read, "f of n is big oh of g of n".
# formal definition or {cross reference} to an entry
@FORML=
$f(n) = O(g(n))$
means there are positive
constants $c$ and $k$, such that 
$0 \leq f(n) \leq cg(n)$ for all
$n \geq k$.
The values of $c$ and $k$ must be fixed for the function
$f$ and must not depend on $n$.
<BR>
<IMG src="../Images/bigOGraph.gif" height="261" width="453" alt="graph
showing relation between a function, f, and the limit function, g">
# comma-sep list of pure names or {cross refs} that this is Also Known As.
@AKA=O
# other cross-listings solely for the web, such as word or spelling variants
@WEB=O notation, Landau symbol

#    These are all comma-separated lists of {cross references}
# Generalization: "I am a kind of ..."
@IMA=
# Specialization: "... is a kind of me."
@VARIANT=
# Aggregate parent: "I am a part of or used in ..."
@IMIN=
# Aggregate child: "... is a part of or used in me."
@INME=
# Other cross references that don't fit the above.  printed as "See also ..."
@XREFS={$\Omega(n)$#\Omega},{$\omega(n)$#\omega},
{$\Theta(n)$#\Theta}, {$\sim$},
{little-o notation}, {asymptotic upper bound}, 
{asymptotically tight bound}, {NP}, {complexity}, {model of computation}

# bib refs, eg, to defining article (pure HTML).  printed within <P>..</P>
@BIB=
<strong>Donald E. Knuth</strong>, <em>Big Omicron and Big Omega and
Big Theta</em>, SIGACT News, 8(2):18-24, April-June 1976.
# Some sources give last page as 23.  The article proper ends on page
# 23, but bibliographical references continue to page 24.

# any notes.  these will not be printed in the final dictionary
@NOTES=
As an example, $n<sup>2</sup> + 3n + 4$ is $O(n<sup>2</sup>)$,
since n<sup>2</sup> + 3n + 4 &lt; 2n<sup>2</sup> for all $n
&gt; 10$.  Strictly speaking, 3n + 4 is $O(n<sup>2</sup>)$, too, but
big-O notation is often misused to mean equal to rather than less than.
The notion of "equal to" is expressed by {$\Theta(n)$#\Theta}.
</P>

<P>
The importance of this measure can be seen in trying to decide whether
an algorithm is adequate, but may just need a better implementation,
or the algorithm will always be too slow on a big enough input.  For
instance, {quicksort}, which is O(n log n) on average, running on
a small desktop computer can beat {bubble sort}, which is
O(n<sup>2</sup>), running on a supercomputer if there are a lot of
numbers to sort.  To sort 1,000,000 numbers, the quicksort takes
20,000,000 steps on average, while the bubble sort takes
1,000,000,000,000 steps!
</P>

<P>
Any measure of execution must implicitly or explicitly refer to some
computation model.  Usually this is some notion of the limiting
factor.  For one problem or machine, the number of
floating point multiplications may be the limiting factor, while for
another, it may be the number of messages passed across a network.
Other measures which may be important are compares, item moves,
disk accesses, memory used, or elapsed ("wall clock") time.
</P>

<P>
Strictly, the character is the upper-case Greek letter Omicron, not
the letter O, but who can tell the difference?
# further explanation (pure HTML)
@LINKS=<A
href="http://www.cs.strath.ac.uk/~mdd/teaching/alg&comp/big_oh.html">A
rough guide to big-oh notation</A> by Mark Dunlop.
George S. Lueker's
<A href="http://www.ics.uci.edu/~lueker/23/notation.pdf">Notation for
growth rates</A> (in PDF).
Big O is a
<A href="http://mathworld.wolfram.com/LandauSymbols.html">Landau Symbol</A>.
# implementation(s) (pure HTML)
@IMPL=
# author's initials
@AUTHOR=PEB
# end $Source: /home/black/Workspace/dads/Terms/RCS/bigOnotation.trm,v $
